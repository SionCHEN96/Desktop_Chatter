/**
 * Fish Speech Test Server
 * Provides Fish Speech API proxy and test web services
 */

import express from 'express';
import cors from 'cors';
import path from 'path';
import fs from 'fs';
import { fileURLToPath } from 'url';
import FormData from 'form-data';

/**
 * Fix text encoding issues
 * @param {string} text - Original text
 * @returns {string} Fixed text
 */
function fixTextEncoding(text) {
  if (!text || typeof text !== 'string') {
    return '';
  }

  let fixedText = text;

  // Check for common encoding error characters
  const encodingIssuePatterns = ['é”›', 'éš', 'æµ£', 'é´', 'é™', 'ç”¯', 'ç‘™', 'é', 'é—‚', 'éš'];
  const hasEncodingIssue = encodingIssuePatterns.some(pattern => text.includes(pattern));

  if (hasEncodingIssue) {
    console.log('[Server] Detected encoding issue, attempting to fix...');
    try {
      const buffer = Buffer.from(text, 'latin1');
      const utf8Text = buffer.toString('utf8');

      // Simple check: if converted text contains more common Chinese characters, use converted text
      const commonChars = ['ä½ ', 'å¥½', 'æ˜¯', 'çš„', 'æˆ‘', 'åœ¨', 'æœ‰', 'äº†', 'ä¸', 'å’Œ', 'äºº', 'è¿™', 'ä¸­', 'å¤§', 'ä¸º'];
      const utf8Score = commonChars.reduce((score, char) => score + (utf8Text.includes(char) ? 1 : 0), 0);
      const originalScore = commonChars.reduce((score, char) => score + (text.includes(char) ? 1 : 0), 0);

      if (utf8Score > originalScore) {
        fixedText = utf8Text;
        console.log('[Server] Encoding fix successful');
      }
    } catch (error) {
      console.warn('[Server] Failed to fix encoding:', error);
    }
  }

  return fixedText;
}

/**
 * Clean text content
 * @param {string} text - Original text
 * @returns {string} Cleaned text
 */
function cleanTextForTTS(text) {
  if (!text || typeof text !== 'string') {
    return '';
  }

  let cleanedText = text;

  // è¿‡æ»¤è¡¨æƒ…ç¬¦å·
  const emojiRegex = /[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu;
  cleanedText = cleanedText.replace(emojiRegex, '');

  // è¿‡æ»¤åŠ¨ä½œæè¿°
  const actionPatterns = [
    /\*[^*]*\*/g,  // è¿‡æ»¤ *åŠ¨ä½œ* æ ¼å¼
    /\([^)]*\)/g,  // è¿‡æ»¤ (è¡¨æƒ…) æ ¼å¼
    /ã€[^ã€‘]*ã€‘/g,  // è¿‡æ»¤ ã€åŠ¨ä½œã€‘ æ ¼å¼
    /\[[^\]]*\]/g  // è¿‡æ»¤ [è¡¨æƒ…] æ ¼å¼
  ];

  actionPatterns.forEach(pattern => {
    cleanedText = cleanedText.replace(pattern, '');
  });

  // æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
  cleanedText = cleanedText.replace(/\s+/g, ' ').trim();

  return cleanedText;
}

/**
 * Comprehensive text processing
 * @param {string} text - Original text
 * @returns {string} Processed text
 */
function processTextForTTS(text) {
  const fixedText = fixTextEncoding(text);
  const cleanedText = cleanTextForTTS(fixedText);
  return cleanedText;
}

// Get __dirname in ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const PORT = 3002;

// Fish Speech API configuration
const FISH_SPEECH_CONFIG = {
  // Local Fish Speech API address (if deployed locally)
  LOCAL_API_URL: 'http://localhost:8081',

  // Hugging Face Space API (backup)
  HF_SPACE_URL: 'https://fishaudio-openaudio-s1-mini.hf.space',

  // Supported languages
  SUPPORTED_LANGUAGES: [
    'en', 'zh', 'ja', 'de', 'fr', 'es', 'ko', 'ar', 'ru', 'nl', 'it', 'pl', 'pt'
  ],
  
  // æƒ…æ„Ÿæ ‡è®°
  EMOTION_MARKERS: [
    '(angry)', '(sad)', '(excited)', '(surprised)', '(satisfied)', '(delighted)',
    '(scared)', '(worried)', '(upset)', '(nervous)', '(frustrated)', '(depressed)',
    '(empathetic)', '(embarrassed)', '(disgusted)', '(moved)', '(proud)', '(relaxed)',
    '(grateful)', '(confident)', '(interested)', '(curious)', '(confused)', '(joyful)',
    '(disdainful)', '(unhappy)', '(anxious)', '(hysterical)', '(indifferent)',
    '(impatient)', '(guilty)', '(scornful)', '(panicked)', '(furious)', '(reluctant)'
  ],
  
  // è¯­è°ƒæ ‡è®°
  TONE_MARKERS: [
    '(in a hurry tone)', '(shouting)', '(screaming)', '(whispering)', '(soft tone)'
  ],
  
  // ç‰¹æ®Šæ•ˆæœ
  SPECIAL_EFFECTS: [
    '(laughing)', '(chuckling)', '(sobbing)', '(crying loudly)', '(sighing)',
    '(panting)', '(groaning)', '(crowd laughing)', '(background laughter)', '(audience laughing)'
  ]
};

// ä¸­é—´ä»¶
app.use(cors({
  origin: '*',
  methods: ['GET', 'POST', 'OPTIONS', 'HEAD'],
  allowedHeaders: ['Content-Type', 'Authorization', 'Range'],
  exposedHeaders: ['Content-Length', 'Content-Range', 'Accept-Ranges'],
  credentials: false
}));
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// é™æ€æ–‡ä»¶æœåŠ¡ï¼Œæ·»åŠ éŸ³é¢‘æ–‡ä»¶çš„ç‰¹æ®Šå¤„ç†
const generatedAudioPath = path.join(__dirname, 'generated_audio');
console.log('[Server] Setting up static audio serving from:', generatedAudioPath);

app.use('/generated_audio', express.static(generatedAudioPath, {
  setHeaders: (res, filePath) => {
    console.log('[Server] Serving audio file:', filePath);
    if (filePath.endsWith('.wav')) {
      res.setHeader('Content-Type', 'audio/wav');
    } else if (filePath.endsWith('.mp3')) {
      res.setHeader('Content-Type', 'audio/mpeg');
    }
    res.setHeader('Accept-Ranges', 'bytes');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Access-Control-Allow-Origin', '*');
  }
}));

// æ·»åŠ éŸ³é¢‘ç›®å½•åˆ—è¡¨åŠŸèƒ½
app.get('/generated_audio/', (req, res) => {
  try {
    console.log('[Server] Audio directory listing requested');
    const files = fs.readdirSync(generatedAudioPath)
      .filter(file => file.endsWith('.wav') || file.endsWith('.mp3'))
      .sort((a, b) => {
        const statA = fs.statSync(path.join(generatedAudioPath, a));
        const statB = fs.statSync(path.join(generatedAudioPath, b));
        return statB.mtime - statA.mtime; // æœ€æ–°çš„åœ¨å‰
      });

    console.log('[Server] Found audio files:', files.length);

    let html = `
      <!DOCTYPE html>
      <html>
      <head>
        <title>Generated Audio Files</title>
        <style>
          body { font-family: Arial, sans-serif; margin: 20px; }
          .file { margin: 10px 0; padding: 10px; border: 1px solid #ddd; border-radius: 5px; }
          .file a { text-decoration: none; color: #007bff; font-weight: bold; }
          .file .info { color: #666; font-size: 12px; margin-top: 5px; }
        </style>
      </head>
      <body>
        <h1>Generated Audio Files (${files.length} files)</h1>
    `;

    files.forEach(file => {
      const filePath = path.join(generatedAudioPath, file);
      const stats = fs.statSync(filePath);
      const size = (stats.size / 1024).toFixed(2);
      const mtime = stats.mtime.toLocaleString();

      html += `
        <div class="file">
          <a href="/generated_audio/${file}" target="_blank">${file}</a>
          <div class="info">Size: ${size} KB | Modified: ${mtime}</div>
        </div>
      `;
    });

    html += `
      </body>
      </html>
    `;

    res.setHeader('Content-Type', 'text/html');
    res.send(html);
  } catch (error) {
    console.error('[Server] Error listing audio files:', error);
    res.status(500).json({ error: 'Failed to list audio files' });
  }
});

app.use(express.static(__dirname));

/**
 * å¥åº·æ£€æŸ¥
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'ok',
    service: 'Fish Speech Test Server',
    timestamp: new Date().toISOString(),
    config: {
      supportedLanguages: FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES,
      emotionMarkersCount: FISH_SPEECH_CONFIG.EMOTION_MARKERS.length,
      toneMarkersCount: FISH_SPEECH_CONFIG.TONE_MARKERS.length,
      specialEffectsCount: FISH_SPEECH_CONFIG.SPECIAL_EFFECTS.length
    }
  });
});

// éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨APIç«¯ç‚¹
app.get('/api/audio/list', (req, res) => {
  try {
    const files = fs.readdirSync(generatedAudioPath)
      .filter(file => file.endsWith('.wav') || file.endsWith('.mp3'))
      .map(file => {
        const filePath = path.join(generatedAudioPath, file);
        const stats = fs.statSync(filePath);
        return {
          filename: file,
          url: `/generated_audio/${file}`,
          size: stats.size,
          modified: stats.mtime.toISOString()
        };
      })
      .sort((a, b) => new Date(b.modified) - new Date(a.modified));

    res.json({
      success: true,
      files: files,
      count: files.length
    });
  } catch (error) {
    console.error('[Server] Error listing audio files:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to list audio files'
    });
  }
});

// è·å–æœ€æ–°éŸ³é¢‘æ–‡ä»¶
app.get('/api/audio/latest', (req, res) => {
  try {
    const files = fs.readdirSync(generatedAudioPath)
      .filter(file => file.endsWith('.wav') || file.endsWith('.mp3'))
      .map(file => {
        const filePath = path.join(generatedAudioPath, file);
        const stats = fs.statSync(filePath);
        return {
          filename: file,
          url: `/generated_audio/${file}`,
          fullUrl: `http://localhost:3002/generated_audio/${file}`,
          size: stats.size,
          modified: stats.mtime.toISOString()
        };
      })
      .sort((a, b) => new Date(b.modified) - new Date(a.modified));

    if (files.length > 0) {
      res.json({
        success: true,
        latest: files[0]
      });
    } else {
      res.json({
        success: false,
        error: 'No audio files found'
      });
    }
  } catch (error) {
    console.error('[Server] Error getting latest audio file:', error);
    res.status(500).json({
      success: false,
      error: 'Failed to get latest audio file'
    });
  }
});

/**
 * è·å–é…ç½®ä¿¡æ¯
 */
app.get('/api/config', (req, res) => {
  res.json({
    languages: FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES,
    emotions: FISH_SPEECH_CONFIG.EMOTION_MARKERS,
    tones: FISH_SPEECH_CONFIG.TONE_MARKERS,
    effects: FISH_SPEECH_CONFIG.SPECIAL_EFFECTS
  });
});

/**
 * Check Fish Speech service status
 */
app.get('/api/fish-speech/status', async (req, res) => {
  try {
    console.log('[Server] Checking Fish Speech service status...');

    // Try to connect to local Fish Speech API
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 5000);

    try {
      const response = await fetch(`${FISH_SPEECH_CONFIG.LOCAL_API_URL}/health`, {
        method: 'GET',
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (response.ok) {
        const responseText = await response.text();
        console.log('[Server] âœ… Local Fish Speech service available');

        res.json({
          status: 'available',
          type: 'local',
          url: FISH_SPEECH_CONFIG.LOCAL_API_URL,
          message: 'Local Fish Speech service available',
          response: responseText,
          timestamp: new Date().toISOString()
        });
        return;
      }
    } catch (localError) {
      clearTimeout(timeoutId);
      console.log('[Server] Local service check failed:', localError.message);
    }

    // Local service unavailable, check Hugging Face Space
    console.log('[Server] Checking Hugging Face Space...');
    try {
      const hfController = new AbortController();
      const hfTimeoutId = setTimeout(() => hfController.abort(), 10000);

      const hfResponse = await fetch(`${FISH_SPEECH_CONFIG.HF_SPACE_URL}/`, {
        method: 'GET',
        signal: hfController.signal
      });

      clearTimeout(hfTimeoutId);

      if (hfResponse.ok) {
        console.log('âœ… Hugging Face Spaceå¯ç”¨');
        res.json({
          status: 'available',
          type: 'huggingface',
          url: FISH_SPEECH_CONFIG.HF_SPACE_URL,
          message: 'Hugging Face Spaceå¯ç”¨ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰',
          timestamp: new Date().toISOString()
        });
        return;
      }
    } catch (hfError) {
      console.log('Hugging Faceæ£€æŸ¥å¤±è´¥:', hfError.message);
    }

    // æ‰€æœ‰æœåŠ¡éƒ½ä¸å¯ç”¨
    console.log('âŒ æ‰€æœ‰Fish SpeechæœåŠ¡éƒ½ä¸å¯ç”¨');
    res.json({
      status: 'unavailable',
      message: 'Fish SpeechæœåŠ¡ä¸å¯ç”¨',
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥:', error);
    res.status(500).json({
      status: 'error',
      message: 'æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * Fish Speech TTSåˆæˆ
 */
app.post('/api/fish-speech/synthesize', async (req, res) => {
  try {
    const { text, reference_audio, reference_text, language = 'auto' } = req.body;
    
    if (!text) {
      return res.status(400).json({
        error: 'Text is required',
        message: 'è¯·æä¾›è¦åˆæˆçš„æ–‡æœ¬'
      });
    }
    
    console.log(`[${new Date().toISOString()}] Fish Speech synthesis request:`, {
      textLength: text.length,
      language,
      hasReferenceAudio: !!reference_audio,
      hasReferenceText: !!reference_text
    });
    
    // é¦–å…ˆå°è¯•æœ¬åœ°API
    let response;
    let usedMethod = 'unknown';

    try {
      console.log('å°è¯•æœ¬åœ°Fish Speech API...');
      response = await synthesizeWithAPI(FISH_SPEECH_CONFIG.LOCAL_API_URL, {
        text,
        reference_audio,
        reference_text,
        language
      });
      usedMethod = 'local';
    } catch (localError) {
      console.log('æœ¬åœ°APIå¤±è´¥ï¼Œå°è¯•Hugging Face Space...');
      try {
        response = await synthesizeWithHuggingFace({
          text,
          reference_audio,
          reference_text,
          language
        });
        usedMethod = 'huggingface';
      } catch (hfError) {
        console.log('Hugging Faceå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨TTS...');
        response = await synthesizeWithBackupTTS({
          text,
          reference_audio,
          reference_text,
          language
        });
        usedMethod = 'backup';
      }
    }
    
    if (response && response.ok) {
      const audioBuffer = await response.arrayBuffer();
      
      res.set({
        'Content-Type': 'audio/wav',
        'Content-Length': audioBuffer.byteLength,
        'Cache-Control': 'no-cache',
        'Access-Control-Allow-Origin': '*'
      });
      
      res.send(Buffer.from(audioBuffer));
      
      console.log(`[${new Date().toISOString()}] Fish Speech synthesis completed:`, {
        audioSize: audioBuffer.byteLength,
        method: usedMethod
      });
    } else {
      throw new Error('åˆæˆå¤±è´¥');
    }
    
  } catch (error) {
    console.error(`[${new Date().toISOString()}] Fish Speech synthesis failed:`, error);
    
    res.status(500).json({
      error: 'Synthesis failed',
      message: error.message || 'è¯­éŸ³åˆæˆå¤±è´¥',
      suggestions: [
        'æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦è¿è¡Œ',
        'ç¡®è®¤æ–‡æœ¬æ ¼å¼æ­£ç¡®',
        'æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ ¼å¼'
      ]
    });
  }
});

/**
 * ä½¿ç”¨æœ¬åœ°Fish Speech APIè¿›è¡Œåˆæˆ
 */
async function synthesizeWithAPI(apiUrl, params) {
  try {
    // é¦–å…ˆæ£€æŸ¥Fish SpeechæœåŠ¡å¥åº·çŠ¶æ€
    console.log('æ£€æŸ¥Fish SpeechæœåŠ¡å¥åº·çŠ¶æ€...');
    const healthResponse = await fetch(`${apiUrl}/v1/health`, {
      method: 'GET',
      timeout: 5000
    });

    if (!healthResponse.ok) {
      throw new Error('Fish SpeechæœåŠ¡ä¸å¯ç”¨');
    }

    console.log('Fish SpeechæœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡');

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: params.text,
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1
    };

    // å¦‚æœæœ‰å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
    if (params.reference_audio && params.reference_text) {
      ttsRequest.reference_audio = params.reference_audio;
      ttsRequest.reference_text = params.reference_text;
    }

    console.log(`è°ƒç”¨Fish Speech API: ${apiUrl}/v1/tts`);
    console.log('è¯·æ±‚å‚æ•°:', {
      textLength: params.text.length,
      hasReference: !!(params.reference_audio && params.reference_text)
    });

    const response = await fetch(`${apiUrl}/v1/tts`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest),
      timeout: 60000 // TTSå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    });

    if (response.ok) {
      console.log('Fish Speech APIè°ƒç”¨æˆåŠŸ');
      return response;
    } else {
      const errorText = await response.text();
      console.error('Fish Speech APIé”™è¯¯:', response.status, errorText);
      throw new Error(`Fish Speech APIå¤±è´¥: ${response.status}`);
    }

  } catch (error) {
    console.error('æœ¬åœ°Fish Speech APIè°ƒç”¨å¤±è´¥:', error);
    throw error;
  }
}

/**
 * ç®€å•çš„TTSç«¯ç‚¹ï¼ˆç”¨äºèŠå¤©åº”ç”¨ï¼‰
 */
app.post('/api/tts', async (req, res) => {
  try {
    const { text, referenceAudio, referenceText } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    console.log('TTS request for text:', text);

    // ä½¿ç”¨æ›´å¼ºå¤§çš„æ–‡æœ¬å¤„ç†å‡½æ•°
    let cleanedText = processTextForTTS(text);

    if (referenceAudio && referenceText) {
      console.log('Using voice cloning with reference audio');
    }

    // æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦å¯ç”¨
    try {
      const healthResponse = await fetch('http://localhost:8081/v1/health');
      if (!healthResponse.ok) {
        throw new Error('Fish Speech server not responding');
      }
    } catch (healthError) {
      console.error('Fish Speech health check failed:', healthError);
      return res.status(503).json({
        error: 'Fish Speech server is not available. Please make sure it is running on port 8081.'
      });
    }

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: cleanedText, // ä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1,
      references: []
    };

    // å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­è¿›è¡Œå£°éŸ³å…‹éš†
    if (referenceAudio && referenceText) {
      try {
        // å‚è€ƒéŸ³é¢‘åº”è¯¥æ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²
        const audioBytes = Buffer.from(referenceAudio, 'base64');
        ttsRequest.references = [{
          audio: referenceAudio, // Fish Speech APIä¼šè‡ªåŠ¨è§£ç base64
          text: referenceText
        }];
        console.log(`Added reference audio: ${audioBytes.length} bytes, text: "${referenceText}"`);
      } catch (error) {
        console.error('Failed to process reference audio:', error);
        return res.status(400).json({ error: 'Invalid reference audio format. Expected base64 encoded audio.' });
      }
    }

    console.log('Sending TTS request to Fish Speech API...');
    const ttsResponse = await fetch('http://localhost:8081/v1/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest)
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('Fish Speech TTS failed:', ttsResponse.status, errorText);

      // å°è¯•è§£æé”™è¯¯ä¿¡æ¯
      let errorDetails = errorText;
      try {
        const errorJson = JSON.parse(errorText);
        errorDetails = errorJson.message || errorJson.error || errorText;
      } catch (e) {
        // å¦‚æœä¸æ˜¯JSONï¼Œä½¿ç”¨åŸå§‹é”™è¯¯æ–‡æœ¬
      }

      return res.status(500).json({
        error: `Fish Speech TTS failed: ${ttsResponse.status}`,
        details: errorDetails,
        originalText: text,
        cleanedText: cleanedText
      });
    }

    // è·å–éŸ³é¢‘æ•°æ®
    const audioBuffer = await ttsResponse.arrayBuffer();
    console.log(`TTS successful, audio size: ${audioBuffer.byteLength} bytes`);

    // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    const timestamp = Date.now();
    const filename = `tts_${timestamp}.wav`;
    const audioDir = path.join(__dirname, 'generated_audio');
    const filepath = path.join(audioDir, filename);

    // åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if (!fs.existsSync(audioDir)) {
      fs.mkdirSync(audioDir, { recursive: true });
    }

    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    fs.writeFileSync(filepath, Buffer.from(audioBuffer));

    res.json({
      success: true,
      message: 'TTS completed successfully',
      audioUrl: `/generated_audio/${filename}`,
      audioSize: audioBuffer.byteLength,
      usedVoiceCloning: !!(referenceAudio && referenceText)
    });

  } catch (error) {
    console.error('TTS error:', error);
    res.status(500).json({ error: 'TTS service error: ' + error.message });
  }
});

// æä¾›ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
app.use('/generated_audio', express.static(path.join(__dirname, 'generated_audio'), {
  setHeaders: (res, path) => {
    if (path.endsWith('.wav')) {
      res.set('Content-Type', 'audio/wav');
      res.set('Cache-Control', 'no-cache');
      res.set('Access-Control-Allow-Origin', '*');
    }
  }
}));

/**
 * å£°éŸ³å…‹éš†ç«¯ç‚¹ï¼ˆæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰
 */
import multer from 'multer';
const upload = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

app.post('/api/voice-clone', upload.single('referenceAudio'), async (req, res) => {
  try {
    const { text, referenceText } = req.body;
    const referenceAudioFile = req.file;

    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    if (!referenceAudioFile || !referenceText) {
      return res.status(400).json({
        error: 'Both reference audio file and reference text are required for voice cloning'
      });
    }

    console.log('Voice cloning request:');
    console.log(`- Text: ${text}`);
    console.log(`- Reference text: ${referenceText}`);
    console.log(`- Reference audio: ${referenceAudioFile.originalname} (${referenceAudioFile.size} bytes)`);

    // æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦å¯ç”¨
    try {
      const healthResponse = await fetch('http://localhost:8081/v1/health');
      if (!healthResponse.ok) {
        throw new Error('Fish Speech server not responding');
      }
    } catch (healthError) {
      console.error('Fish Speech health check failed:', healthError);
      return res.status(503).json({
        error: 'Fish Speech server is not available. Please make sure it is running on port 8081.'
      });
    }

    // å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºbase64
    const audioBase64 = referenceAudioFile.buffer.toString('base64');

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: text,
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1,
      references: [{
        audio: audioBase64,
        text: referenceText
      }]
    };

    console.log('Sending voice cloning request to Fish Speech API...');
    const ttsResponse = await fetch('http://localhost:8081/v1/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest)
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('Fish Speech voice cloning failed:', ttsResponse.status, errorText);
      return res.status(500).json({
        error: `Fish Speech voice cloning failed: ${ttsResponse.status}`
      });
    }

    // è·å–éŸ³é¢‘æ•°æ®
    const audioBuffer = await ttsResponse.arrayBuffer();
    console.log(`Voice cloning successful, audio size: ${audioBuffer.byteLength} bytes`);

    // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    const timestamp = Date.now();
    const filename = `voice_clone_${timestamp}.wav`;
    const audioDir = path.join(__dirname, 'generated_audio');
    const filepath = path.join(audioDir, filename);

    // åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if (!fs.existsSync(audioDir)) {
      fs.mkdirSync(audioDir, { recursive: true });
    }

    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    fs.writeFileSync(filepath, Buffer.from(audioBuffer));

    res.json({
      success: true,
      message: 'Voice cloning completed successfully',
      audioUrl: `/generated_audio/${filename}`,
      audioSize: audioBuffer.byteLength,
      referenceAudioSize: referenceAudioFile.size,
      referenceText: referenceText
    });

  } catch (error) {
    console.error('Voice cloning error:', error);
    res.status(500).json({ error: 'Voice cloning service error: ' + error.message });
  }
});

/**
 * ä½¿ç”¨Hugging Face Spaceè¿›è¡Œåˆæˆ
 */
async function synthesizeWithHuggingFace(params) {
  console.log('ä½¿ç”¨Hugging Face Spaceåˆæˆ...');

  try {
    // æ–¹æ³•1: å°è¯•Gradio APIæ¥å£
    const gradioResponse = await synthesizeWithGradio(params);
    if (gradioResponse) return gradioResponse;

    // æ–¹æ³•2: å°è¯•ç›´æ¥APIè°ƒç”¨
    const directResponse = await synthesizeWithDirectAPI(params);
    if (directResponse) return directResponse;

    // æ–¹æ³•3: ä½¿ç”¨å¤‡ç”¨TTSæœåŠ¡
    const backupResponse = await synthesizeWithBackupTTS(params);
    if (backupResponse) return backupResponse;

    throw new Error('æ‰€æœ‰Hugging Faceæ–¹æ³•éƒ½å¤±è´¥');

  } catch (error) {
    console.error('Hugging Faceåˆæˆå¤±è´¥:', error);
    throw error;
  }
}

/**
 * ä½¿ç”¨Gradio APIè¿›è¡Œåˆæˆ
 */
async function synthesizeWithGradio(params) {
  try {
    const spaceUrl = 'https://fishaudio-openaudio-s1-mini.hf.space';

    // æ„å»ºGradio APIè¯·æ±‚
    const gradioData = {
      data: [
        params.text,                    // æ–‡æœ¬
        params.reference_audio || null, // å‚è€ƒéŸ³é¢‘
        params.reference_text || '',    // å‚è€ƒæ–‡æœ¬
        params.language || 'auto'       // è¯­è¨€
      ]
    };

    console.log('è°ƒç”¨Gradio API:', spaceUrl);

    const response = await fetch(`${spaceUrl}/api/predict`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(gradioData),
      timeout: 60000 // Gradioå¯èƒ½æ¯”è¾ƒæ…¢
    });

    if (response.ok) {
      const result = await response.json();

      // Gradioè¿”å›çš„æ•°æ®æ ¼å¼å¯èƒ½æ˜¯ {data: [audio_url]}
      if (result.data && result.data[0]) {
        const audioUrl = result.data[0];

        // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        const audioResponse = await fetch(audioUrl);
        if (audioResponse.ok) {
          console.log('Gradio APIåˆæˆæˆåŠŸ');
          return audioResponse;
        }
      }
    }

    throw new Error('Gradio APIè°ƒç”¨å¤±è´¥');

  } catch (error) {
    console.log('Gradioæ–¹æ³•å¤±è´¥:', error.message);
    return null;
  }
}

/**
 * ä½¿ç”¨ç›´æ¥APIè°ƒç”¨
 */
async function synthesizeWithDirectAPI(params) {
  try {
    // å°è¯•Fish Audioçš„åœ¨çº¿APIï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    const apiEndpoints = [
      'https://api.fish.audio/v1/tts',
      'https://fishaudio-openaudio-s1-mini.hf.space/api/tts'
    ];

    for (const endpoint of apiEndpoints) {
      try {
        console.log('å°è¯•ç›´æ¥API:', endpoint);

        const requestBody = {
          text: params.text,
          language: params.language || 'auto'
        };

        if (params.reference_audio) {
          requestBody.reference_audio = params.reference_audio;
        }

        if (params.reference_text) {
          requestBody.reference_text = params.reference_text;
        }

        const response = await fetch(endpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(requestBody),
          timeout: 30000
        });

        if (response.ok) {
          console.log('ç›´æ¥APIè°ƒç”¨æˆåŠŸ');
          return response;
        }

      } catch (endpointError) {
        console.log(`ç«¯ç‚¹ ${endpoint} å¤±è´¥:`, endpointError.message);
        continue;
      }
    }

    throw new Error('æ‰€æœ‰ç›´æ¥APIç«¯ç‚¹éƒ½å¤±è´¥');

  } catch (error) {
    console.log('ç›´æ¥APIæ–¹æ³•å¤±è´¥:', error.message);
    return null;
  }
}

/**
 * å¤‡ç”¨TTSæœåŠ¡ï¼ˆå½“Fish Speechä¸å¯ç”¨æ—¶ï¼‰
 */
async function synthesizeWithBackupTTS(params) {
  try {
    console.log('Fish SpeechæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³åˆæˆ');
    throw new Error('Fish Speech service unavailable');
  } catch (error) {
    console.log('TTSæœåŠ¡å¤±è´¥:', error.message);
    throw error;
  }
}

/**
 * ç”Ÿæˆæ¼”ç¤ºéŸ³é¢‘ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
 */
async function generateDemoAudio(text, language = 'zh') {
  // åˆ›å»ºä¸€ä¸ªç®€å•çš„WAVæ–‡ä»¶å¤´
  const sampleRate = 22050;
  const duration = Math.max(3, Math.min(text.length * 0.08, 8)); // 3-8ç§’
  const numSamples = Math.floor(sampleRate * duration);

  // WAVæ–‡ä»¶å¤´ï¼ˆ44å­—èŠ‚ï¼‰
  const header = Buffer.alloc(44);

  // RIFF header
  header.write('RIFF', 0);
  header.writeUInt32LE(36 + numSamples * 2, 4);
  header.write('WAVE', 8);

  // fmt chunk
  header.write('fmt ', 12);
  header.writeUInt32LE(16, 16);
  header.writeUInt16LE(1, 20);  // PCM
  header.writeUInt16LE(1, 22);  // mono
  header.writeUInt32LE(sampleRate, 24);
  header.writeUInt32LE(sampleRate * 2, 28);
  header.writeUInt16LE(2, 32);
  header.writeUInt16LE(16, 34);

  // data chunk
  header.write('data', 36);
  header.writeUInt32LE(numSamples * 2, 40);

  // ç”Ÿæˆæ›´å¤æ‚çš„éŸ³é¢‘æ•°æ®ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„é¢‘ç‡å˜åŒ–ï¼‰
  const audioData = Buffer.alloc(numSamples * 2);

  for (let i = 0; i < numSamples; i++) {
    const t = i / sampleRate;

    // åŸºç¡€é¢‘ç‡ï¼ˆæ¨¡æ‹Ÿäººå£°ï¼‰
    const baseFreq = language === 'zh' ? 200 : 180; // ä¸­æ–‡ç¨é«˜

    // æ·»åŠ é¢‘ç‡å˜åŒ–ï¼ˆæ¨¡æ‹Ÿè¯­è°ƒï¼‰
    const freqModulation = Math.sin(2 * Math.PI * 0.5 * t) * 50;
    const frequency = baseFreq + freqModulation;

    // æ·»åŠ éŸ³é‡åŒ…ç»œï¼ˆå¼€å§‹å’Œç»“æŸæ¸å˜ï¼‰
    let envelope = 1;
    const fadeTime = 0.1; // 0.1ç§’æ¸å˜
    if (t < fadeTime) {
      envelope = t / fadeTime;
    } else if (t > duration - fadeTime) {
      envelope = (duration - t) / fadeTime;
    }

    // æ·»åŠ ä¸€äº›è°æ³¢ï¼ˆä½¿å£°éŸ³æ›´è‡ªç„¶ï¼‰
    const fundamental = Math.sin(2 * Math.PI * frequency * t);
    const harmonic2 = Math.sin(2 * Math.PI * frequency * 2 * t) * 0.3;
    const harmonic3 = Math.sin(2 * Math.PI * frequency * 3 * t) * 0.1;

    // æ·»åŠ è½»å¾®çš„å™ªéŸ³ï¼ˆæ¨¡æ‹Ÿå‘¼å¸å£°ï¼‰
    const noise = (Math.random() - 0.5) * 0.02;

    const sample = (fundamental + harmonic2 + harmonic3 + noise) * envelope * 0.3;
    const intSample = Math.floor(sample * 32767);
    audioData.writeInt16LE(Math.max(-32768, Math.min(32767, intSample)), i * 2);
  }

  console.log(`ç”Ÿæˆæ¼”ç¤ºéŸ³é¢‘: ${duration.toFixed(1)}ç§’, ${numSamples}é‡‡æ ·ç‚¹`);
  return Buffer.concat([header, audioData]);
}

/**
 * å¯åŠ¨æœåŠ¡å™¨
 */
app.listen(PORT, () => {
  console.log('ğŸŸ Fish Speech æµ‹è¯•æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!');
  console.log(`ğŸ“± æµ‹è¯•é¡µé¢: http://localhost:${PORT}/index.html`);
  console.log(`ğŸ”§ APIç«¯ç‚¹: http://localhost:${PORT}/api/fish-speech/synthesize`);
  console.log(`ğŸ“Š å¥åº·æ£€æŸ¥: http://localhost:${PORT}/api/health`);
  console.log(`âš™ï¸  é…ç½®ä¿¡æ¯: http://localhost:${PORT}/api/config`);
  console.log('');
  console.log('ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½:');
  console.log(`- æ”¯æŒ ${FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES.length} ç§è¯­è¨€`);
  console.log(`- ${FISH_SPEECH_CONFIG.EMOTION_MARKERS.length} ç§æƒ…æ„Ÿæ ‡è®°`);
  console.log(`- ${FISH_SPEECH_CONFIG.TONE_MARKERS.length} ç§è¯­è°ƒæ ‡è®°`);
  console.log(`- ${FISH_SPEECH_CONFIG.SPECIAL_EFFECTS.length} ç§ç‰¹æ®Šæ•ˆæœ`);
  console.log('');
  console.log('âš ï¸  æ³¨æ„: éœ€è¦æœ¬åœ°éƒ¨ç½²Fish SpeechæœåŠ¡æˆ–ä½¿ç”¨Hugging Face Space');
});

// ä¼˜é›…å…³é—­
process.on('SIGINT', () => {
  console.log('\nğŸ›‘ æ­£åœ¨å…³é—­Fish Speechæµ‹è¯•æœåŠ¡å™¨...');
  process.exit(0);
});

process.on('SIGTERM', () => {
  console.log('\nğŸ›‘ æ­£åœ¨å…³é—­Fish Speechæµ‹è¯•æœåŠ¡å™¨...');
  process.exit(0);
});
