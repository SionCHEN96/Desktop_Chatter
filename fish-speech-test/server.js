/**
 * Fish Speech æµ‹è¯•æœåŠ¡å™¨
 * æä¾›Fish Speech APIçš„ä»£ç†å’Œæµ‹è¯•ç½‘é¡µæœåŠ¡
 */

import express from 'express';
import cors from 'cors';
import path from 'path';
import fs from 'fs';
import { fileURLToPath } from 'url';
import FormData from 'form-data';

// ESæ¨¡å—ä¸­è·å–__dirname
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const PORT = 3002;

// Fish Speech APIé…ç½®
const FISH_SPEECH_CONFIG = {
  // æœ¬åœ°Fish Speech APIåœ°å€ï¼ˆå¦‚æœæœ¬åœ°éƒ¨ç½²ï¼‰
  LOCAL_API_URL: 'http://localhost:8080',
  
  // Hugging Face Space APIï¼ˆå¤‡ç”¨ï¼‰
  HF_SPACE_URL: 'https://fishaudio-openaudio-s1-mini.hf.space',
  
  // æ”¯æŒçš„è¯­è¨€
  SUPPORTED_LANGUAGES: [
    'en', 'zh', 'ja', 'de', 'fr', 'es', 'ko', 'ar', 'ru', 'nl', 'it', 'pl', 'pt'
  ],
  
  // æƒ…æ„Ÿæ ‡è®°
  EMOTION_MARKERS: [
    '(angry)', '(sad)', '(excited)', '(surprised)', '(satisfied)', '(delighted)',
    '(scared)', '(worried)', '(upset)', '(nervous)', '(frustrated)', '(depressed)',
    '(empathetic)', '(embarrassed)', '(disgusted)', '(moved)', '(proud)', '(relaxed)',
    '(grateful)', '(confident)', '(interested)', '(curious)', '(confused)', '(joyful)',
    '(disdainful)', '(unhappy)', '(anxious)', '(hysterical)', '(indifferent)',
    '(impatient)', '(guilty)', '(scornful)', '(panicked)', '(furious)', '(reluctant)'
  ],
  
  // è¯­è°ƒæ ‡è®°
  TONE_MARKERS: [
    '(in a hurry tone)', '(shouting)', '(screaming)', '(whispering)', '(soft tone)'
  ],
  
  // ç‰¹æ®Šæ•ˆæœ
  SPECIAL_EFFECTS: [
    '(laughing)', '(chuckling)', '(sobbing)', '(crying loudly)', '(sighing)',
    '(panting)', '(groaning)', '(crowd laughing)', '(background laughter)', '(audience laughing)'
  ]
};

// ä¸­é—´ä»¶
app.use(cors());
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));
app.use(express.static(__dirname));

/**
 * å¥åº·æ£€æŸ¥
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'ok',
    service: 'Fish Speech Test Server',
    timestamp: new Date().toISOString(),
    config: {
      supportedLanguages: FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES,
      emotionMarkersCount: FISH_SPEECH_CONFIG.EMOTION_MARKERS.length,
      toneMarkersCount: FISH_SPEECH_CONFIG.TONE_MARKERS.length,
      specialEffectsCount: FISH_SPEECH_CONFIG.SPECIAL_EFFECTS.length
    }
  });
});

/**
 * è·å–é…ç½®ä¿¡æ¯
 */
app.get('/api/config', (req, res) => {
  res.json({
    languages: FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES,
    emotions: FISH_SPEECH_CONFIG.EMOTION_MARKERS,
    tones: FISH_SPEECH_CONFIG.TONE_MARKERS,
    effects: FISH_SPEECH_CONFIG.SPECIAL_EFFECTS
  });
});

/**
 * æ£€æŸ¥Fish SpeechæœåŠ¡çŠ¶æ€
 */
app.get('/api/fish-speech/status', async (req, res) => {
  try {
    console.log('æ£€æŸ¥Fish SpeechæœåŠ¡çŠ¶æ€...');

    // å°è¯•è¿æ¥æœ¬åœ°Fish Speech API
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 5000);

    try {
      const response = await fetch(`${FISH_SPEECH_CONFIG.LOCAL_API_URL}/health`, {
        method: 'GET',
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (response.ok) {
        const responseText = await response.text();
        console.log('âœ… æœ¬åœ°Fish SpeechæœåŠ¡å¯ç”¨');

        res.json({
          status: 'available',
          type: 'local',
          url: FISH_SPEECH_CONFIG.LOCAL_API_URL,
          message: 'æœ¬åœ°Fish SpeechæœåŠ¡å¯ç”¨',
          response: responseText,
          timestamp: new Date().toISOString()
        });
        return;
      }
    } catch (localError) {
      clearTimeout(timeoutId);
      console.log('æœ¬åœ°æœåŠ¡æ£€æŸ¥å¤±è´¥:', localError.message);
    }

    // æœ¬åœ°æœåŠ¡ä¸å¯ç”¨ï¼Œæ£€æŸ¥Hugging Face Space
    console.log('æ£€æŸ¥Hugging Face Space...');
    try {
      const hfController = new AbortController();
      const hfTimeoutId = setTimeout(() => hfController.abort(), 10000);

      const hfResponse = await fetch(`${FISH_SPEECH_CONFIG.HF_SPACE_URL}/`, {
        method: 'GET',
        signal: hfController.signal
      });

      clearTimeout(hfTimeoutId);

      if (hfResponse.ok) {
        console.log('âœ… Hugging Face Spaceå¯ç”¨');
        res.json({
          status: 'available',
          type: 'huggingface',
          url: FISH_SPEECH_CONFIG.HF_SPACE_URL,
          message: 'Hugging Face Spaceå¯ç”¨ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰',
          timestamp: new Date().toISOString()
        });
        return;
      }
    } catch (hfError) {
      console.log('Hugging Faceæ£€æŸ¥å¤±è´¥:', hfError.message);
    }

    // æ‰€æœ‰æœåŠ¡éƒ½ä¸å¯ç”¨
    console.log('âŒ æ‰€æœ‰Fish SpeechæœåŠ¡éƒ½ä¸å¯ç”¨');
    res.json({
      status: 'unavailable',
      type: 'demo',
      message: 'Fish SpeechæœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼',
      suggestions: [
        '1. è¿è¡Œ quick_deploy.bat éƒ¨ç½²æœ¬åœ°æœåŠ¡',
        '2. è¿è¡Œ start_fish_speech.bat å¯åŠ¨æœåŠ¡',
        '3. ç­‰å¾…æœåŠ¡å¯åŠ¨å®Œæˆï¼ˆ1-2åˆ†é’Ÿï¼‰',
        '4. åˆ·æ–°é¡µé¢é‡æ–°æ£€æŸ¥'
      ],
      deploymentGuide: {
        quickDeploy: 'quick_deploy.bat',
        startService: 'start_fish_speech.bat',
        checkService: 'node check_fish_speech.js'
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥:', error);
    res.status(500).json({
      status: 'error',
      message: 'æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * Fish Speech TTSåˆæˆ
 */
app.post('/api/fish-speech/synthesize', async (req, res) => {
  try {
    const { text, reference_audio, reference_text, language = 'auto' } = req.body;
    
    if (!text) {
      return res.status(400).json({
        error: 'Text is required',
        message: 'è¯·æä¾›è¦åˆæˆçš„æ–‡æœ¬'
      });
    }
    
    console.log(`[${new Date().toISOString()}] Fish Speech synthesis request:`, {
      textLength: text.length,
      language,
      hasReferenceAudio: !!reference_audio,
      hasReferenceText: !!reference_text
    });
    
    // é¦–å…ˆå°è¯•æœ¬åœ°API
    let response;
    let usedMethod = 'unknown';

    try {
      console.log('å°è¯•æœ¬åœ°Fish Speech API...');
      response = await synthesizeWithAPI(FISH_SPEECH_CONFIG.LOCAL_API_URL, {
        text,
        reference_audio,
        reference_text,
        language
      });
      usedMethod = 'local';
    } catch (localError) {
      console.log('æœ¬åœ°APIå¤±è´¥ï¼Œå°è¯•Hugging Face Space...');
      try {
        response = await synthesizeWithHuggingFace({
          text,
          reference_audio,
          reference_text,
          language
        });
        usedMethod = 'huggingface';
      } catch (hfError) {
        console.log('Hugging Faceå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨TTS...');
        response = await synthesizeWithBackupTTS({
          text,
          reference_audio,
          reference_text,
          language
        });
        usedMethod = 'backup';
      }
    }
    
    if (response && response.ok) {
      const audioBuffer = await response.arrayBuffer();
      
      res.set({
        'Content-Type': 'audio/wav',
        'Content-Length': audioBuffer.byteLength,
        'Content-Disposition': `attachment; filename="fish-speech-${Date.now()}.wav"`
      });
      
      res.send(Buffer.from(audioBuffer));
      
      console.log(`[${new Date().toISOString()}] Fish Speech synthesis completed:`, {
        audioSize: audioBuffer.byteLength,
        method: usedMethod
      });
    } else {
      throw new Error('åˆæˆå¤±è´¥');
    }
    
  } catch (error) {
    console.error(`[${new Date().toISOString()}] Fish Speech synthesis failed:`, error);
    
    res.status(500).json({
      error: 'Synthesis failed',
      message: error.message || 'è¯­éŸ³åˆæˆå¤±è´¥',
      suggestions: [
        'æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦è¿è¡Œ',
        'ç¡®è®¤æ–‡æœ¬æ ¼å¼æ­£ç¡®',
        'æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ ¼å¼'
      ]
    });
  }
});

/**
 * ä½¿ç”¨æœ¬åœ°Fish Speech APIè¿›è¡Œåˆæˆ
 */
async function synthesizeWithAPI(apiUrl, params) {
  try {
    // é¦–å…ˆæ£€æŸ¥Fish SpeechæœåŠ¡å¥åº·çŠ¶æ€
    console.log('æ£€æŸ¥Fish SpeechæœåŠ¡å¥åº·çŠ¶æ€...');
    const healthResponse = await fetch(`${apiUrl}/v1/health`, {
      method: 'GET',
      timeout: 5000
    });

    if (!healthResponse.ok) {
      throw new Error('Fish SpeechæœåŠ¡ä¸å¯ç”¨');
    }

    console.log('Fish SpeechæœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡');

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: params.text,
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1
    };

    // å¦‚æœæœ‰å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
    if (params.reference_audio && params.reference_text) {
      ttsRequest.reference_audio = params.reference_audio;
      ttsRequest.reference_text = params.reference_text;
    }

    console.log(`è°ƒç”¨Fish Speech API: ${apiUrl}/v1/tts`);
    console.log('è¯·æ±‚å‚æ•°:', {
      textLength: params.text.length,
      hasReference: !!(params.reference_audio && params.reference_text)
    });

    const response = await fetch(`${apiUrl}/v1/tts`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest),
      timeout: 60000 // TTSå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    });

    if (response.ok) {
      console.log('Fish Speech APIè°ƒç”¨æˆåŠŸ');
      return response;
    } else {
      const errorText = await response.text();
      console.error('Fish Speech APIé”™è¯¯:', response.status, errorText);
      throw new Error(`Fish Speech APIå¤±è´¥: ${response.status}`);
    }

  } catch (error) {
    console.error('æœ¬åœ°Fish Speech APIè°ƒç”¨å¤±è´¥:', error);
    throw error;
  }
}

/**
 * ç®€å•çš„TTSç«¯ç‚¹ï¼ˆç”¨äºèŠå¤©åº”ç”¨ï¼‰
 */
app.post('/api/tts', async (req, res) => {
  try {
    const { text, referenceAudio, referenceText } = req.body;

    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    console.log('TTS request for text:', text);
    if (referenceAudio && referenceText) {
      console.log('Using voice cloning with reference audio');
    }

    // æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦å¯ç”¨
    try {
      const healthResponse = await fetch('http://localhost:8080/v1/health');
      if (!healthResponse.ok) {
        throw new Error('Fish Speech server not responding');
      }
    } catch (healthError) {
      console.error('Fish Speech health check failed:', healthError);
      return res.status(503).json({
        error: 'Fish Speech server is not available. Please make sure it is running on port 8080.'
      });
    }

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: text,
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1,
      references: []
    };

    // å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­è¿›è¡Œå£°éŸ³å…‹éš†
    if (referenceAudio && referenceText) {
      try {
        // å‚è€ƒéŸ³é¢‘åº”è¯¥æ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²
        const audioBytes = Buffer.from(referenceAudio, 'base64');
        ttsRequest.references = [{
          audio: referenceAudio, // Fish Speech APIä¼šè‡ªåŠ¨è§£ç base64
          text: referenceText
        }];
        console.log(`Added reference audio: ${audioBytes.length} bytes, text: "${referenceText}"`);
      } catch (error) {
        console.error('Failed to process reference audio:', error);
        return res.status(400).json({ error: 'Invalid reference audio format. Expected base64 encoded audio.' });
      }
    }

    console.log('Sending TTS request to Fish Speech API...');
    const ttsResponse = await fetch('http://localhost:8080/v1/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest)
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('Fish Speech TTS failed:', ttsResponse.status, errorText);
      return res.status(500).json({
        error: `Fish Speech TTS failed: ${ttsResponse.status}`
      });
    }

    // è·å–éŸ³é¢‘æ•°æ®
    const audioBuffer = await ttsResponse.arrayBuffer();
    console.log(`TTS successful, audio size: ${audioBuffer.byteLength} bytes`);

    // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    const timestamp = Date.now();
    const filename = `tts_${timestamp}.wav`;
    const audioDir = path.join(__dirname, 'generated_audio');
    const filepath = path.join(audioDir, filename);

    // åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if (!fs.existsSync(audioDir)) {
      fs.mkdirSync(audioDir, { recursive: true });
    }

    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    fs.writeFileSync(filepath, Buffer.from(audioBuffer));

    res.json({
      success: true,
      message: 'TTS completed successfully',
      audioUrl: `/generated_audio/${filename}`,
      audioSize: audioBuffer.byteLength,
      usedVoiceCloning: !!(referenceAudio && referenceText)
    });

  } catch (error) {
    console.error('TTS error:', error);
    res.status(500).json({ error: 'TTS service error: ' + error.message });
  }
});

// æä¾›ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
app.use('/generated_audio', express.static(path.join(__dirname, 'generated_audio')));

/**
 * å£°éŸ³å…‹éš†ç«¯ç‚¹ï¼ˆæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰
 */
import multer from 'multer';
const upload = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

app.post('/api/voice-clone', upload.single('referenceAudio'), async (req, res) => {
  try {
    const { text, referenceText } = req.body;
    const referenceAudioFile = req.file;

    if (!text) {
      return res.status(400).json({ error: 'Text is required' });
    }

    if (!referenceAudioFile || !referenceText) {
      return res.status(400).json({
        error: 'Both reference audio file and reference text are required for voice cloning'
      });
    }

    console.log('Voice cloning request:');
    console.log(`- Text: ${text}`);
    console.log(`- Reference text: ${referenceText}`);
    console.log(`- Reference audio: ${referenceAudioFile.originalname} (${referenceAudioFile.size} bytes)`);

    // æ£€æŸ¥Fish SpeechæœåŠ¡æ˜¯å¦å¯ç”¨
    try {
      const healthResponse = await fetch('http://localhost:8080/v1/health');
      if (!healthResponse.ok) {
        throw new Error('Fish Speech server not responding');
      }
    } catch (healthError) {
      console.error('Fish Speech health check failed:', healthError);
      return res.status(503).json({
        error: 'Fish Speech server is not available. Please make sure it is running on port 8080.'
      });
    }

    // å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºbase64
    const audioBase64 = referenceAudioFile.buffer.toString('base64');

    // æ„å»ºFish Speech APIè¯·æ±‚
    const ttsRequest = {
      text: text,
      format: "wav",
      chunk_length: 200,
      normalize: true,
      temperature: 0.8,
      top_p: 0.8,
      repetition_penalty: 1.1,
      references: [{
        audio: audioBase64,
        text: referenceText
      }]
    };

    console.log('Sending voice cloning request to Fish Speech API...');
    const ttsResponse = await fetch('http://localhost:8080/v1/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(ttsRequest)
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('Fish Speech voice cloning failed:', ttsResponse.status, errorText);
      return res.status(500).json({
        error: `Fish Speech voice cloning failed: ${ttsResponse.status}`
      });
    }

    // è·å–éŸ³é¢‘æ•°æ®
    const audioBuffer = await ttsResponse.arrayBuffer();
    console.log(`Voice cloning successful, audio size: ${audioBuffer.byteLength} bytes`);

    // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    const timestamp = Date.now();
    const filename = `voice_clone_${timestamp}.wav`;
    const audioDir = path.join(__dirname, 'generated_audio');
    const filepath = path.join(audioDir, filename);

    // åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if (!fs.existsSync(audioDir)) {
      fs.mkdirSync(audioDir, { recursive: true });
    }

    // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    fs.writeFileSync(filepath, Buffer.from(audioBuffer));

    res.json({
      success: true,
      message: 'Voice cloning completed successfully',
      audioUrl: `/generated_audio/${filename}`,
      audioSize: audioBuffer.byteLength,
      referenceAudioSize: referenceAudioFile.size,
      referenceText: referenceText
    });

  } catch (error) {
    console.error('Voice cloning error:', error);
    res.status(500).json({ error: 'Voice cloning service error: ' + error.message });
  }
});

/**
 * ä½¿ç”¨Hugging Face Spaceè¿›è¡Œåˆæˆ
 */
async function synthesizeWithHuggingFace(params) {
  console.log('ä½¿ç”¨Hugging Face Spaceåˆæˆ...');

  try {
    // æ–¹æ³•1: å°è¯•Gradio APIæ¥å£
    const gradioResponse = await synthesizeWithGradio(params);
    if (gradioResponse) return gradioResponse;

    // æ–¹æ³•2: å°è¯•ç›´æ¥APIè°ƒç”¨
    const directResponse = await synthesizeWithDirectAPI(params);
    if (directResponse) return directResponse;

    // æ–¹æ³•3: ä½¿ç”¨å¤‡ç”¨TTSæœåŠ¡
    const backupResponse = await synthesizeWithBackupTTS(params);
    if (backupResponse) return backupResponse;

    throw new Error('æ‰€æœ‰Hugging Faceæ–¹æ³•éƒ½å¤±è´¥');

  } catch (error) {
    console.error('Hugging Faceåˆæˆå¤±è´¥:', error);
    throw error;
  }
}

/**
 * ä½¿ç”¨Gradio APIè¿›è¡Œåˆæˆ
 */
async function synthesizeWithGradio(params) {
  try {
    const spaceUrl = 'https://fishaudio-openaudio-s1-mini.hf.space';

    // æ„å»ºGradio APIè¯·æ±‚
    const gradioData = {
      data: [
        params.text,                    // æ–‡æœ¬
        params.reference_audio || null, // å‚è€ƒéŸ³é¢‘
        params.reference_text || '',    // å‚è€ƒæ–‡æœ¬
        params.language || 'auto'       // è¯­è¨€
      ]
    };

    console.log('è°ƒç”¨Gradio API:', spaceUrl);

    const response = await fetch(`${spaceUrl}/api/predict`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(gradioData),
      timeout: 60000 // Gradioå¯èƒ½æ¯”è¾ƒæ…¢
    });

    if (response.ok) {
      const result = await response.json();

      // Gradioè¿”å›çš„æ•°æ®æ ¼å¼å¯èƒ½æ˜¯ {data: [audio_url]}
      if (result.data && result.data[0]) {
        const audioUrl = result.data[0];

        // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        const audioResponse = await fetch(audioUrl);
        if (audioResponse.ok) {
          console.log('Gradio APIåˆæˆæˆåŠŸ');
          return audioResponse;
        }
      }
    }

    throw new Error('Gradio APIè°ƒç”¨å¤±è´¥');

  } catch (error) {
    console.log('Gradioæ–¹æ³•å¤±è´¥:', error.message);
    return null;
  }
}

/**
 * ä½¿ç”¨ç›´æ¥APIè°ƒç”¨
 */
async function synthesizeWithDirectAPI(params) {
  try {
    // å°è¯•Fish Audioçš„åœ¨çº¿APIï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    const apiEndpoints = [
      'https://api.fish.audio/v1/tts',
      'https://fishaudio-openaudio-s1-mini.hf.space/api/tts'
    ];

    for (const endpoint of apiEndpoints) {
      try {
        console.log('å°è¯•ç›´æ¥API:', endpoint);

        const requestBody = {
          text: params.text,
          language: params.language || 'auto'
        };

        if (params.reference_audio) {
          requestBody.reference_audio = params.reference_audio;
        }

        if (params.reference_text) {
          requestBody.reference_text = params.reference_text;
        }

        const response = await fetch(endpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(requestBody),
          timeout: 30000
        });

        if (response.ok) {
          console.log('ç›´æ¥APIè°ƒç”¨æˆåŠŸ');
          return response;
        }

      } catch (endpointError) {
        console.log(`ç«¯ç‚¹ ${endpoint} å¤±è´¥:`, endpointError.message);
        continue;
      }
    }

    throw new Error('æ‰€æœ‰ç›´æ¥APIç«¯ç‚¹éƒ½å¤±è´¥');

  } catch (error) {
    console.log('ç›´æ¥APIæ–¹æ³•å¤±è´¥:', error.message);
    return null;
  }
}

/**
 * ä½¿ç”¨å¤‡ç”¨TTSæœåŠ¡
 */
async function synthesizeWithBackupTTS(params) {
  try {
    console.log('ä½¿ç”¨å¤‡ç”¨TTSæœåŠ¡ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰...');

    // åˆ›å»ºä¸€ä¸ªåŒ…å«æç¤ºä¿¡æ¯çš„éŸ³é¢‘
    const demoText = `Fish Speechæ¼”ç¤ºæ¨¡å¼ã€‚æ‚¨è¾“å…¥çš„æ–‡æœ¬æ˜¯ï¼š${params.text.substring(0, 50)}${params.text.length > 50 ? '...' : ''}`;
    const mockAudio = await generateDemoAudio(demoText, params.language);

    return new Response(mockAudio, {
      headers: {
        'Content-Type': 'audio/wav',
        'Content-Length': mockAudio.length
      }
    });

  } catch (error) {
    console.log('å¤‡ç”¨TTSå¤±è´¥:', error.message);
    throw error;
  }
}

/**
 * ç”Ÿæˆæ¼”ç¤ºéŸ³é¢‘ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
 */
async function generateDemoAudio(text, language = 'zh') {
  // åˆ›å»ºä¸€ä¸ªç®€å•çš„WAVæ–‡ä»¶å¤´
  const sampleRate = 22050;
  const duration = Math.max(3, Math.min(text.length * 0.08, 8)); // 3-8ç§’
  const numSamples = Math.floor(sampleRate * duration);

  // WAVæ–‡ä»¶å¤´ï¼ˆ44å­—èŠ‚ï¼‰
  const header = Buffer.alloc(44);

  // RIFF header
  header.write('RIFF', 0);
  header.writeUInt32LE(36 + numSamples * 2, 4);
  header.write('WAVE', 8);

  // fmt chunk
  header.write('fmt ', 12);
  header.writeUInt32LE(16, 16);
  header.writeUInt16LE(1, 20);  // PCM
  header.writeUInt16LE(1, 22);  // mono
  header.writeUInt32LE(sampleRate, 24);
  header.writeUInt32LE(sampleRate * 2, 28);
  header.writeUInt16LE(2, 32);
  header.writeUInt16LE(16, 34);

  // data chunk
  header.write('data', 36);
  header.writeUInt32LE(numSamples * 2, 40);

  // ç”Ÿæˆæ›´å¤æ‚çš„éŸ³é¢‘æ•°æ®ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„é¢‘ç‡å˜åŒ–ï¼‰
  const audioData = Buffer.alloc(numSamples * 2);

  for (let i = 0; i < numSamples; i++) {
    const t = i / sampleRate;

    // åŸºç¡€é¢‘ç‡ï¼ˆæ¨¡æ‹Ÿäººå£°ï¼‰
    const baseFreq = language === 'zh' ? 200 : 180; // ä¸­æ–‡ç¨é«˜

    // æ·»åŠ é¢‘ç‡å˜åŒ–ï¼ˆæ¨¡æ‹Ÿè¯­è°ƒï¼‰
    const freqModulation = Math.sin(2 * Math.PI * 0.5 * t) * 50;
    const frequency = baseFreq + freqModulation;

    // æ·»åŠ éŸ³é‡åŒ…ç»œï¼ˆå¼€å§‹å’Œç»“æŸæ¸å˜ï¼‰
    let envelope = 1;
    const fadeTime = 0.1; // 0.1ç§’æ¸å˜
    if (t < fadeTime) {
      envelope = t / fadeTime;
    } else if (t > duration - fadeTime) {
      envelope = (duration - t) / fadeTime;
    }

    // æ·»åŠ ä¸€äº›è°æ³¢ï¼ˆä½¿å£°éŸ³æ›´è‡ªç„¶ï¼‰
    const fundamental = Math.sin(2 * Math.PI * frequency * t);
    const harmonic2 = Math.sin(2 * Math.PI * frequency * 2 * t) * 0.3;
    const harmonic3 = Math.sin(2 * Math.PI * frequency * 3 * t) * 0.1;

    // æ·»åŠ è½»å¾®çš„å™ªéŸ³ï¼ˆæ¨¡æ‹Ÿå‘¼å¸å£°ï¼‰
    const noise = (Math.random() - 0.5) * 0.02;

    const sample = (fundamental + harmonic2 + harmonic3 + noise) * envelope * 0.3;
    const intSample = Math.floor(sample * 32767);
    audioData.writeInt16LE(Math.max(-32768, Math.min(32767, intSample)), i * 2);
  }

  console.log(`ç”Ÿæˆæ¼”ç¤ºéŸ³é¢‘: ${duration.toFixed(1)}ç§’, ${numSamples}é‡‡æ ·ç‚¹`);
  return Buffer.concat([header, audioData]);
}

/**
 * å¯åŠ¨æœåŠ¡å™¨
 */
app.listen(PORT, () => {
  console.log('ğŸŸ Fish Speech æµ‹è¯•æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!');
  console.log(`ğŸ“± æµ‹è¯•é¡µé¢: http://localhost:${PORT}/index.html`);
  console.log(`ğŸ”§ APIç«¯ç‚¹: http://localhost:${PORT}/api/fish-speech/synthesize`);
  console.log(`ğŸ“Š å¥åº·æ£€æŸ¥: http://localhost:${PORT}/api/health`);
  console.log(`âš™ï¸  é…ç½®ä¿¡æ¯: http://localhost:${PORT}/api/config`);
  console.log('');
  console.log('ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½:');
  console.log(`- æ”¯æŒ ${FISH_SPEECH_CONFIG.SUPPORTED_LANGUAGES.length} ç§è¯­è¨€`);
  console.log(`- ${FISH_SPEECH_CONFIG.EMOTION_MARKERS.length} ç§æƒ…æ„Ÿæ ‡è®°`);
  console.log(`- ${FISH_SPEECH_CONFIG.TONE_MARKERS.length} ç§è¯­è°ƒæ ‡è®°`);
  console.log(`- ${FISH_SPEECH_CONFIG.SPECIAL_EFFECTS.length} ç§ç‰¹æ®Šæ•ˆæœ`);
  console.log('');
  console.log('âš ï¸  æ³¨æ„: éœ€è¦æœ¬åœ°éƒ¨ç½²Fish SpeechæœåŠ¡æˆ–ä½¿ç”¨Hugging Face Space');
});

// ä¼˜é›…å…³é—­
process.on('SIGINT', () => {
  console.log('\nğŸ›‘ æ­£åœ¨å…³é—­Fish Speechæµ‹è¯•æœåŠ¡å™¨...');
  process.exit(0);
});

process.on('SIGTERM', () => {
  console.log('\nğŸ›‘ æ­£åœ¨å…³é—­Fish Speechæµ‹è¯•æœåŠ¡å™¨...');
  process.exit(0);
});
